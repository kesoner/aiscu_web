// geminiService.ts
import { GoogleGenAI } from "@google/genai";
import { DocumentChunk, AgentStep } from "../types/rag";

// ===================================================
// INIT: Singleton AI Client
// ===================================================

let ai: GoogleGenAI | null = null;

const getAI = () => {
  if (!ai) {
    const apiKey = import.meta.env.VITE_API_KEY;
    if (!apiKey) {
      console.error("CRITICAL: VITE_API_KEY is missing!");
      throw new Error("API Key missing");
    }
    ai = new GoogleGenAI({ apiKey });
  }
  return ai;
};

export const checkApiKey = (): boolean => !!import.meta.env.VITE_API_KEY;

// ===================================================
// MODELS
// ===================================================

const EMBEDDING_MODEL = "text-multilingual-embedding-002";
const GENERATION_MODEL = "gemini-2.5-flash";

// ===================================================
// EMBEDDING SERVICE
// ===================================================

export const getEmbeddings = async (texts: string[]): Promise<number[][]> => {
  try {
    const results = await Promise.all(
      texts.map(async (text) => {
        const res = await getAI().models.embedContent({
          model: EMBEDDING_MODEL,
          contents: [{ parts: [{ text }] }],
        });
        return res.embeddings?.[0]?.values ?? [];
      })
    );
    return results;
  } catch (error) {
    console.error("âŒ Error generating embeddings:", error);
    throw new Error("Embedding generation failed");
  }
};

// ===================================================
// File -> InlineData Part
// ===================================================

const fileToPart = (
  file: File
): Promise<{ inlineData: { data: string; mimeType: string } }> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onerror = reject;

    reader.onloadend = () => {
      const base64 = (reader.result as string).split(",")[1];
      resolve({
        inlineData: { data: base64, mimeType: file.type },
      });
    };

    reader.readAsDataURL(file);
  });
};

// ===================================================
// MULTIMODAL FILE PROCESSOR
// ===================================================

export const processImportedFile = async (
  file: File
): Promise<{ title: string; category: string; content: string }> => {
  const filePart = await fileToPart(file);

  const systemPrompt = `
    ä½ æ˜¯ä¸€å€‹è³‡æ–™åº«æ­¸æª”å°ˆå“¡ (Archivist)ã€‚
    ä»»å‹™ï¼šè§£ææª”æ¡ˆå…§å®¹ä¸¦è¼¸å‡º JSONã€‚

    {
      "title": "ç²¾ç¢ºæ¨™é¡Œ",
      "category": "DOCUMENT | EVIDENCE | AUDIO_LOG | IMG_DATA | MEETING_NOTE",
      "content": "OCRã€æ‘˜è¦æˆ–é€å­—ç¨¿ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"
    }

    åš´ç¦ Markdownï¼Œå¿…é ˆç‚ºç´” JSONã€‚
  `;

  try {
    const result = await getAI().models.generateContent({
      model: GENERATION_MODEL,
      config: { responseMimeType: "application/json" },
      contents: [
        { role: "user", parts: [filePart] },
        { role: "user", parts: [{ text: systemPrompt }] },
      ],
    });

    return JSON.parse(result.text?.trim() || "{}");
  } catch (error) {
    console.error("âŒ File processing failed:", error);
    throw new Error("ç„¡æ³•è§£ææª”æ¡ˆå…§å®¹");
  }
};

// ===================================================
// URL PROCESSOR (Jina Reader)
// ===================================================

export const processWebUrl = async (
  url: string
): Promise<{ title: string; category: string; content: string }> => {
  try {
    const scrapeRes = await fetch(`https://r.jina.ai/${url}`);
    if (!scrapeRes.ok) throw new Error("Failed to fetch URL");

    const markdown = await scrapeRes.text();

    const prompt = `
      ä½ æ˜¯ä¸€å€‹ç¶²è·¯æƒ…è³‡æ”¶é›†å“¡ï¼Œè«‹æ‘˜è¦ä»¥ä¸‹å…§å®¹ï¼š

      ${markdown.substring(0, 30000)}

      é¡¯ç¤ºæ ¼å¼ï¼šç´” JSONã€‚

      {
        "title": "ç¶²é æ¨™é¡Œ",
        "category": "WEB_ARCHIVE",
        "content": "ç¹ä¸­æ‘˜è¦"
      }
    `;

    const result = await getAI().models.generateContent({
      model: GENERATION_MODEL,
      config: { responseMimeType: "application/json" },
      contents: [{ role: "user", parts: [{ text: prompt }] }],
    });

    return JSON.parse(result.text?.trim() || "{}");
  } catch (error) {
    console.error("âŒ Web scraping failed:", error);
    throw new Error("ç„¡æ³•è®€å–ç¶²é å…§å®¹");
  }
};

// ===================================================
// FINAL ANSWER GENERATOR
// ===================================================

export const generateFinalAnswer = async (
  query: string,
  contextText: string
): Promise<string> => {
  const systemInstruction = `
ä½ æ˜¯ AISCUï¼ˆæ±å³å¤§å­¸äººå·¥æ™ºæ…§æ‡‰ç”¨ç¤¾ï¼‰çš„å®˜æ–¹ AI å°åŠ©æ‰‹ã€‚

=== å›ç­”åŸå‰‡ ===
1. è‹¥ Context æœ‰æ˜ç¢ºè³‡è¨Š â†’ çµ•å°å„ªå…ˆå¼•ç”¨ã€‚
2. ç¦æ­¢æé€ ä¸å­˜åœ¨çš„æ™‚é–“ã€ç¤¾è²»ã€è¦å‰‡ã€‚
3. è‹¥ Context å…§å®¹ä¸è¶³ä½†å•é¡Œå±¬æ–¼å®˜æ–¹è³‡è¨Šï¼š
   â†’ å›ç­”å¾Œè£œä¸€å¥ï¼šã€Œè©³ç´°è³‡è¨Šè«‹æ´½è©¢ç¤¾åœ˜å¹¹éƒ¨å–”ï½ã€
4. èªæ°£æº«æŸ”ã€è¦ªåˆ‡ã€è‡ªç„¶ï¼Œå¯ç¨å¾®å¯æ„›ï¼ˆğŸ˜Šâœ¨ï¼‰

=== Context ===
${contextText || "(æŸ¥ç„¡è³‡æ–™)"}

=== Query ===
${query}
`;

  const res = await getAI().models.generateContent({
    model: GENERATION_MODEL,
    config: {
      systemInstruction,
      temperature: 0.7,
    },
    contents: [{ role: "user", parts: [{ text: query }] }],
  });

  return res.text || "SYSTEM_ERR: ç„¡æ³•ç”¢ç”Ÿå›æ‡‰ã€‚";
};

// ===================================================
// RAG MAIN PIPELINE
// ===================================================

export async function* runAgenticRag(
  query: string,
  retriever: (q: string) => Promise<DocumentChunk[]>
): AsyncGenerator<AgentStep> {
  yield {
    type: "log",
    message: `INIT: åŸ·è¡Œå‘é‡æª¢ç´¢... query="${query}"`,
  };

  const chunks = await retriever(query);

  const context =
    chunks.length > 0 ? chunks.map((c) => c.text).join("\n---\n") : "";

  yield {
    type: "log",
    message:
      chunks.length > 0
        ? `RAG: æ‰¾åˆ° ${chunks.length} ç­†å…§å®¹ï¼Œäº¤çµ¦æ¨¡å‹ç”Ÿæˆå›ç­”`
        : `RAG: æŸ¥ç„¡ç›¸é—œè³‡æ–™ï¼Œå°‡ä»¥ã€Œç„¡ contextã€æ¨¡å¼å›è¦†`,
  };

  yield { type: "log", message: "GENERATING: æ­£åœ¨ç”Ÿæˆæœ€çµ‚å›è¦†..." };

  const answer = await generateFinalAnswer(query, context);

  yield {
    type: "answer",
    message: answer,
    source: chunks.length > 0 ? "RAG_DATA" : "NO_DATA",
  };
}
