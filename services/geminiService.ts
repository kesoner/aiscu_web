// geminiService.ts
import { GoogleGenAI } from "@google/genai";
import { DocumentChunk, AgentStep } from "../src/types/rag";

// ----------------------------------------------------
// INIT
// ----------------------------------------------------

let ai: GoogleGenAI | null = null;

const getAI = () => {
  if (!ai) {
    const apiKey = import.meta.env.VITE_API_KEY;
    if (!apiKey) {
      console.error("CRITICAL: VITE_API_KEY is missing!");
      throw new Error("API Key missing");
    }
    ai = new GoogleGenAI({ apiKey });
  }
  return ai;
};

export const checkApiKey = (): boolean => {
  return !!import.meta.env.VITE_API_KEY;
};

const EMBEDDING_MODEL = "text-embedding-004";
const GENERATION_MODEL = "gemini-2.5-flash";

// ----------------------------------------------------
//  EMBEDDING
// ----------------------------------------------------
export const getEmbeddings = async (texts: string[]): Promise<number[][]> => {
  try {
    const results = await Promise.all(
      texts.map(async (text) => {
        const res = await getAI().models.embedContent({
          model: EMBEDDING_MODEL,
          contents: { parts: [{ text }] },
        });
        return res.embeddings?.[0]?.values || [];
      })
    );
    return results;
  } catch (error) {
    console.error("Error generating embeddings:", error);
    throw error;
  }
};

// ----------------------------------------------------
//  INGESTION & MULTIMODAL PROCESSING
// ----------------------------------------------------

const fileToPart = (file: File): Promise<{ inlineData: { data: string; mimeType: string } }> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      const base64String = (reader.result as string).split(',')[1];
      resolve({
        inlineData: {
          data: base64String,
          mimeType: file.type,
        },
      });
    };
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
};

/**
 * è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ (PDF, Image, Audio, Video)
 * ä½¿ç”¨ Gemini çš„å¤šæ¨¡æ…‹èƒ½åŠ›æå–è³‡è¨Š
 */
export const processImportedFile = async (file: File): Promise<{ title: string; category: string; content: string }> => {
  const filePart = await fileToPart(file);

  const systemPrompt = `
  ä½ æ˜¯ä¸€å€‹è³‡æ–™åº«æ­¸æª”å°ˆå“¡ (Archivist)ã€‚
  ä»»å‹™ï¼šåˆ†æä¸Šå‚³çš„æª”æ¡ˆå…§å®¹ï¼Œä¸¦æå–çµæ§‹åŒ–è³‡è¨Šä»¥å­˜å…¥è³‡æ–™åº«ã€‚
  
  è¼¸å‡ºæ ¼å¼ (JSON):
  {
    "title": "ç°¡çŸ­ç²¾ç¢ºçš„æ¨™é¡Œ",
    "category": "åˆ†é¡ä»£ç¢¼ (å¦‚: DOCUMENT, EVIDENCE, AUDIO_LOG, IMG_DATA, MEETING_NOTE)",
    "content": "è©³ç´°çš„å…§å®¹æ‘˜è¦ã€OCRæ–‡å­—æˆ–è½å¯«é€å­—ç¨¿ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡ã€‚"
  }
  
  æ³¨æ„ï¼šç›´æ¥å›å‚³ JSON ç‰©ä»¶ï¼Œä¸è¦ä½¿ç”¨ Markdown æ ¼å¼ã€‚
  `;

  try {
    const result = await getAI().models.generateContent({
      model: GENERATION_MODEL,
      config: { responseMimeType: "application/json" },
      contents: [{ role: 'user', parts: [filePart, { text: systemPrompt }] }]
    });

    const text = result.text?.trim() || "{}";
    return JSON.parse(text);
  } catch (e) {
    console.error("File processing failed", e);
    throw new Error("ç„¡æ³•è§£ææª”æ¡ˆå…§å®¹");
  }
};

/**
 * è™•ç†ç¶²é é€£çµ
 * é€é r.jina.ai ç²å–å…§å®¹å¾Œæ‘˜è¦
 */
export const processWebUrl = async (url: string): Promise<{ title: string; category: string; content: string }> => {
  try {
    // Fetch markdown from Jina Reader
    const scrapeRes = await fetch(`https://r.jina.ai/${url}`);
    if (!scrapeRes.ok) throw new Error("Failed to fetch URL");
    const markdown = await scrapeRes.text();

    const prompt = `
        ä½ æ˜¯ä¸€å€‹ç¶²è·¯æƒ…è³‡æ”¶é›†å“¡ã€‚
        ä»»å‹™ï¼šåˆ†æä»¥ä¸‹ç¶²é å…§å®¹ï¼Œæå–é—œéµè³‡è¨Šã€‚

        ç¶²é å…§å®¹:
        ${markdown.substring(0, 30000)} 
        
        è¼¸å‡ºæ ¼å¼ (JSON):
        {
            "title": "ç¶²é æ¨™é¡Œ",
            "category": "WEB_ARCHIVE",
            "content": "ç¶²é é‡é»æ‘˜è¦ (ç¹é«”ä¸­æ–‡)"
        }
        ç›´æ¥å›å‚³ JSONã€‚
        `;

    const result = await getAI().models.generateContent({
      model: GENERATION_MODEL,
      config: { responseMimeType: "application/json" },
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });

    const text = result.text?.trim() || "{}";
    return JSON.parse(text);
  } catch (e) {
    console.error("Web scraping failed", e);
    throw new Error("ç„¡æ³•è®€å–ç¶²é å…§å®¹");
  }
};

// ----------------------------------------------------
//  FINAL ANSWER GENERATOR (Updated)
// ----------------------------------------------------

export const generateFinalAnswer = async (
  query: string,
  contextText: string
): Promise<string> => {

  const systemInstruction = `
ä½ æ˜¯ AISCUï¼ˆæ±å³å¤§å­¸äººå·¥æ™ºæ…§æ‡‰ç”¨ç¤¾ï¼‰çš„å®˜æ–¹ AI å°åŠ©æ‰‹ï¼Œ
æ“æœ‰ã€Œä¸€èˆ¬èŠå¤©èƒ½åŠ›ã€èˆ‡ã€Œè³‡æ–™åº«æŸ¥è©¢è¼”åŠ©èƒ½åŠ›ã€ã€‚

ä½ çš„è¼¸å…¥åŒ…å«ï¼š
1. ä½¿ç”¨è€…å•é¡Œï¼ˆQueryï¼‰
2. è³‡æ–™åº«æª¢ç´¢çµæœï¼ˆContextï¼‰ï¼Œå¯èƒ½æ˜¯ç©ºçš„ã€‚

=== å›ç­”è¦å‰‡ ===

1. å¦‚æœ Context ä¸­æœ‰æ˜ç¢ºè³‡è¨Šï¼ˆä¾‹å¦‚ç¤¾è²»é‡‘é¡ã€ç¤¾èª²æ™‚é–“ã€åœ°é»ã€è¦å‰‡ï¼‰ï¼š
   âœ” è«‹å„ªå…ˆä½¿ç”¨å…¶ä¸­çš„äº‹å¯¦ä½œç­”ã€‚
   âœ” ä¸è¦ç·¨é€ ä¸å­˜åœ¨çš„ç´°ç¯€ã€‚

2. å¦‚æœ Context å¹¾ä¹æ²’è³‡è¨Š / å®Œå…¨ä¸ç›¸é—œï¼š
   âœ” è«‹æ­£å¸¸èŠå¤©ã€è‡ªç„¶å›æ‡‰ã€‚
   âœ” å¦‚æœå•é¡Œæ˜é¡¯æ˜¯åœ¨å•ç¤¾åœ˜å®˜æ–¹è³‡è¨Šï¼ˆä¾‹ï¼šç¤¾è²»å¤šå°‘ï¼Ÿæ´»å‹•åœ¨å“ªè£¡ï¼Ÿï¼‰
     è«‹åœ¨å›ç­”æœ€å¾ŒåŠ ä¸€å¥ï¼š
     ã€Œè©³ç´°è³‡è¨Šè«‹æ´½è©¢ç¤¾åœ˜å¹¹éƒ¨å–”ï½ã€

3. èªæ°£é¢¨æ ¼ï¼š
   âœ” ä½¿ç”¨ç¹é«”ä¸­æ–‡
   âœ” æº«æŸ”ã€è¦ªåˆ‡ã€è‡ªç„¶ï¼Œå¯ç¨å¾®å¯æ„›ï¼ˆğŸ˜Šâœ¨ï¼‰
   âœ” åƒä¸€ä½å‹å–„çš„ AISCU å°åŠ©æ‰‹

4. çµ•å°ç¦æ­¢ï¼š
   âœ˜ ç·¨é€ ä¸å­˜åœ¨çš„é‡‘é¡ã€æ™‚é–“ã€åœ°é»ã€è¦å‰‡
   âœ˜ æ­ªæ¨“éé ­ã€ä¸ç›¸é—œå›ç­”

=== INPUT ===
ã€è³‡æ–™åº«æª¢ç´¢çµæœã€‘:
${contextText || "(æŸ¥ç„¡è³‡æ–™)"}

ã€ä½¿ç”¨è€…å•é¡Œã€‘:
${query}

è«‹ä¾ç…§ä»¥ä¸Šè¦å‰‡ç”Ÿæˆæœ€çµ‚å›ç­”ã€‚
`;

  const response = await getAI().models.generateContent({
    model: GENERATION_MODEL,
    config: {
      systemInstruction,
      temperature: 0.7,
    },
    contents: [{ role: "user", parts: [{ text: query }] }],
  });

  return response.text || "SYSTEM_ERR: ç„¡æ³•ç”¢ç”Ÿå›æ‡‰ã€‚";
};




/**
 * RAG ä¸»æµç¨‹
 * æ°¸é ï¼š
 * 1. å…ˆæª¢ç´¢
 * 2. å†äº¤çµ¦æ¨¡å‹ç”Ÿæˆ
 */
export async function* runAgenticRag(
  query: string,
  retriever: (q: string) => Promise<DocumentChunk[]>
): AsyncGenerator<AgentStep> {

  // ----------------------------------------------------
  // STEP 1: Always retrieve
  // ----------------------------------------------------
  yield {
    type: "log",
    message: `INIT: åŸ·è¡Œå‘é‡æª¢ç´¢... Query="${query}"`
  };

  const relevantChunks = await retriever(query);

  // ----------------------------------------------------
  // STEP 2: Build context for LLM
  // ----------------------------------------------------
  let finalContext = "";

  if (relevantChunks.length > 0) {
    finalContext = relevantChunks.map((c) => c.text).join("\n---\n");

    yield {
      type: "log",
      message: `RAG: æ‰¾åˆ° ${relevantChunks.length} ç­†å…§å®¹ï¼Œäº¤ç”±æ¨¡å‹ç”Ÿæˆå›ç­”`
    };
  } else {
    yield {
      type: "log",
      message: `RAG: æŸ¥ç„¡ç›¸é—œè³‡æ–™ï¼Œå°‡ä»¥ã€Œç„¡ contextã€æ¨¡å¼ç”Ÿæˆå›ç­”`
    };
  }

  // ----------------------------------------------------
  // STEP 3: Ask LLM to produce final answer
  // ----------------------------------------------------
  yield { type: "log", message: "GENERATING: æ­£åœ¨ç”Ÿæˆæœ€çµ‚å›è¦†..." };

  const answer = await generateFinalAnswer(query, finalContext);

  yield {
    type: "answer",
    message: answer,
    source: relevantChunks.length > 0 ? "RAG_DATA" : "NO_DATA"
  };
}
